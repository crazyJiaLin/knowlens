产品哲学

和你产生链接的知识才有用

致力于让AI 帮用户真正读懂了原信息

解决方案：扎根于原文知识点，根据知识点生成跳出原文的洞察（知其然，知其所以然）。总结没有意义。



Knowlens 产品需求文档（PRD）
一、产品概述
Knowlens 是一款基于 AI 的知识洞察助手，旨在帮助用户从长文本内容（如视频逐字稿、PDF、网页文章等）中自动提炼出知识点，并生成基于这些知识点的深度洞察。产品面向希望高效理解复杂内容的知识工作者、学生与研究者。
二、核心功能
1. 内容输入
用户可上传 PDF 文件或输入视频 URL，系统会自动将内容转换为可分析的文本格式。
2. 知识点提炼
知识点用原文摘录或轻度改写，且带“原文角标”（anchor），点击角标直接跳转到原文对应位置（视频为时间点，PDF 为页码 + 文本位置）
3. 洞察生成
系统在用户点击“洞察”按钮时生成该知识点的深度解析，内容包括：（1）知识点背后的逻辑、原因或趋势；（2）若用户填写职业或阅读目标，则洞察中可适度结合该背景生成个性化启发。
三、交互设计
4. 知识点以卡片形式展示，原文角标位于右上角。
5. 洞察内容通过点击“洞察”按钮后展开显示，避免信息过载。
6. 支持多源内容输入（视频 URL、PDF 上传、纯文本粘贴）。
四、功能需求
. 输入与预处理
- 支持三种输入：
  - 视频 URL（YouTube、B站 等）：系统将调用转录服务 → 生成时间戳化文本（每段含 start_time, end_time）。
  - PDF 上传：系统提取文本并保留页码与字符偏移（page, start_offset, end_offset）。
  - 文本粘贴：直接作为纯文本，推荐前端分段并返回字符偏移。
- 预处理产物（供 LLM 使用的主数据）：
  - document_id, source_type, title, segments[]（每段含 text, start_time/page, end_time/page, segment_id）
  - language, duration（视频）/pages（PDF）等元数据

- 交互：
  - 异步处理，前端先渲染出卡片，中间展示loding.. ,用户退出页面后可在记录中找到
  - 预处理任务成功后，显示“文本已生成 / 提取完成”并展示，视频展示逐字稿，PDF展示原文
知识点提炼（同步一次性）
- 模型任务（一次性调用）：
  - 入参：content_text（完整或分段）、user_info（role OR goal）, max_knowledge_points（
  - 输出：知识点列表（每个知识点包含 id, topic, excerpt, source_anchor, confidence_score）
{
  "id": "kp_0001",
  "topic": "AI 作为劳动者",
  "excerpt": "“AI 不再是工具，而是会使用工具的‘工人’。”",
  "source_anchor": {
    "type": "video",        // or "pdf" or "text"
    "start_time": 123.5,    // for video (seconds)
    "end_time": 127.0,
    "page": null,           // for pdf
    "start_offset": null,
    "end_offset": null
  },
  "confidence": 0.92
}

  
  
- 交互：
  - 展示逻辑：前端先渲染知识点卡（topic + excerpt + 原文角标），同时不生成洞察内容。
原文角标与跳转
- 每个知识点显示一个小角标／编号（例如[1]），并提供两种交互：[1]
  - 点击角标 → 主阅读区跳转并高亮对应原文段落；若视频则跳到对应时间并播放，同时在原文中跳转展示该时间段的文字与锚点）；若 PDF，则跳到对应页并滚动到偏移位置并高亮。
  - 鼠标悬停角标 → 显示小预览（tooltip）：上下文 1-2 行，和“跳转播放/跳转阅读”按钮。
  技术实现要点：
  - Video: 转录时需记录 time->char mapping，前端播放器支持跳转到 start_time - 2s；
  - PDF: 文本提取时记录 page & char offsets，并支持 PDF viewer 的文本高亮 API（或将原文在 app 内渲染为 HTML 以便跳转）；
  - 文本: 利用字符偏移精确滚动。
洞察按需生成（Lazy insight）
- UI：每个知识点卡右侧放“洞察（查看）”按钮。用户鼠标悬停后可看到洞察按钮，点击该按钮后：
  - 前端发送 generate_insight(kp_id, user_info) 请求到后端。
  - 后端调用 LLM（或走 queued job）以该知识点 + 捕获的上下文段+用户输入的职业（或其他需求）作为输入，返回 insight_text（结构化：logic, hidden_info, optional extension（非必需，有职业信息）。
  - 后端缓存洞察结果（缓存键：document_id + kp_id + user_info），并同时记录生成成本与耗时。
{
  "kp_id": "kp_0001",
  "insight": {
    "logic": "AI 的核心能力从纯执行命令转为理解意图与工具调度...",
    "hidden_info": "这样的表述暗示产业链中间模块可能被重构...",
    "extension_optional": "若用户为产品经理，则可能需要考虑…"
  },
  "generated_at": "2025-11-05T09:00:00Z"
}


- 交互：
  - 点击洞察按钮，该知识卡片展示在顶端，知识卡片下方展示洞察卡片（大卡片）
  - 鼠标悬停到洞察卡片，显示关闭按钮
  - 点击关闭，重新回到知识卡片列表
- 并发/体验策略：
  - 立即显示“生成中” loading 状态；
  - 若 3 秒内无返回，显示中断信息并允许用户选择“继续等待 / 后台生成并通知 / 取消”；
  - 但 UX 上要尽量避免强制等待：优先返回“快速摘要式洞察” + “深入洞察（需更长时间）”。

记录
  - 若用户为登录状态，生成的信息保存为记录
  - 按照时间倒序展示，最新的时间展示在最前面，如内容在解析中，展示解析中字样提示

产品原型

https://www.figma.com/design/rXf26ZPwlJqO4I5QyTT24D/Untitled?node-id=103-313&t=4DqoZQ2J2K1sbQWO-1
性能与成本控制建议
洞察按需生成 是必须（节省 API 调用成本并提升 UX）；
批量预提炼知识点（一次性调用）比每个知识点都调用模型更省钱；知识点生成可做在上传后异步完成；
缓存洞察：同一 document+kp+user_info 不重复调用；支持 TTL 并可手动刷新；
未来规划
- 增加多模态支持（如音频转录）。
- 引入用户知识库，将提炼的知识点与洞察进行长期积累与检索。
- 商业化：
  - 每个月转录的文字不超过 1 万字
  - 洞察（2 个之前免费）2 个之后收费
- 增加知识点收藏，知识点浏览。知识点洞察的收藏
- 增加根据内容，知识点的 chat  功能
